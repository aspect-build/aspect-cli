"""GitHub-aware lint strategy and changed files provider."""

load("./github.axl", "create_review", "create_review_comment", "get_pull_request", "list_review_comments", "delete_review_comment", "list_pull_request_files")
load("./sarif.axl", "parse_sarif", "sarif_to_review_comments")
load("@aspect_rules_lint//lint/lint.axl", "Strategy", "ChangedFilesProvider")


def _parse_github_diff_patch(patch):
    """
    Parse a GitHub file patch string to extract added line numbers.

    Args:
        patch: The patch string from GitHub's files API

    Returns:
        List of 0-based line numbers of added lines
    """
    if not patch:
        return []

    lines = []
    current_line = 0
    for line in patch.split("\n"):
        if line.startswith("@@"):
            # Parse hunk header: @@ -old,count +new,count @@
            parts = line.split(" ")
            for part in parts:
                if part.startswith("+") and part != "+++":
                    plus = part.removeprefix("+")
                    if "," in plus:
                        current_line = int(plus.split(",")[0])
                    else:
                        current_line = int(plus)
                    break
        elif line.startswith("+"):
            # Added line (0-based)
            lines.append(current_line - 1)
            current_line += 1
        elif line.startswith("-"):
            # Deleted line, don't increment current_line
            pass
        else:
            # Context line
            current_line += 1

    return lines


def make_github_changed_files_provider(token, owner, repo):
    """
    Create a ChangedFilesProvider that fetches changed files from the GitHub API.

    Args:
        token: GitHub token
        owner: Repository owner
        repo: Repository name

    Returns:
        ChangedFilesProvider instance
    """
    def get_changed_files(ctx, state):
        ref = ctx.std.env.var("GITHUB_REF") or ""
        if not (ref.startswith("refs/pull/") and ref.endswith("/merge")):
            return []  # not a PR build

        pr_number = int(ref.removeprefix("refs/pull/").removesuffix("/merge"))
        state["pr_number"] = pr_number

        # Fetch changed files from GitHub API
        result = list_pull_request_files(ctx, token, owner, repo, pr_number)
        if not result["success"]:
            return []

        all_files = []
        for f in result["files"]:
            if f.get("status", "") == "removed":
                continue
            filename = f.get("filename", "")
            patch = f.get("patch", "")
            added_lines = _parse_github_diff_patch(patch)
            all_files.append({"file": filename, "lines": added_lines})

        state["changed_lines"] = {f["file"]: f["lines"] for f in all_files}
        return all_files

    return ChangedFilesProvider(get_changed_files = get_changed_files)


def _enrich_with_suggestions(ctx, comments):
    """Read source files and append suggestion blocks for fixable comments."""
    file_cache = {}
    for comment in comments:
        fixes = comment.get("_fixes")
        if not fixes:
            continue

        path = comment["path"]
        if path not in file_cache:
            file_cache[path] = ctx.std.fs.read_to_string(path)
        content = file_cache[path]
        if not content:
            continue

        lines = content.split("\n")
        line_num = comment["line"]
        if line_num < 1 or line_num > len(lines):
            continue

        # Calculate byte offset of the target line start
        line_byte_start = 0
        for i in range(line_num - 1):
            line_byte_start += len(lines[i]) + 1  # +1 for \n

        original_line = lines[line_num - 1]

        # Convert absolute byte offsets to line-relative, filter to this line
        applicable = []
        for f in fixes:
            rel_start = f["byteOffset"] - line_byte_start
            rel_end = rel_start + f["byteLength"]
            if 0 <= rel_start and rel_end <= len(original_line):
                applicable.append({
                    "start": rel_start,
                    "end": rel_end,
                    "replacement": f["replacement"],
                })

        if not applicable:
            continue

        # Apply in reverse position order to preserve earlier offsets
        applicable = sorted(applicable, key = lambda f: f["start"], reverse = True)
        fixed = original_line
        for f in applicable:
            fixed = fixed[:f["start"]] + f["replacement"] + fixed[f["end"]:]

        if fixed != original_line:
            comment["body"] += "\n\n```suggestion\n" + fixed + "\n```"

        # Clean up internal metadata
        comment.pop("_fixes", None)


# =============================================================================
# GitHub Strategy Wrapper
# =============================================================================

def _build_comment_marker(tool, file, line, rule_id):
    """Build a hidden HTML comment marker for identifying lint comments."""
    return "<!-- aspect-lint:{}:{}:{}:{} -->".format(tool, file, line, rule_id)


def _extract_comment_marker(body):
    """Extract the aspect-lint marker from a comment body, or None."""
    prefix = "<!-- aspect-lint:"
    suffix = " -->"
    if not body:
        return None
    idx = body.find(prefix)
    if idx < 0:
        return None
    end = body.find(suffix, idx)
    if end < 0:
        return None
    return body[idx:end + len(suffix)]


def _check_staleness(ctx, state):
    """
    Check if the current run is stale (PR HEAD has moved past our commit).

    Returns True if stale, False otherwise.
    On API failure, assumes NOT stale.
    """
    gh = state["github"]
    pr_number = state.get("pr_number")
    if not pr_number:
        return False

    result = get_pull_request(
        ctx,
        token = gh["token"],
        owner = gh["owner"],
        repo = gh["repo"],
        pull_number = pr_number,
    )

    if not result["success"]:
        # API failure: assume not stale (better to post stale comments than lose results)
        return False

    pr = result["pull_request"]
    head_sha = pr.get("head", {}).get("sha", "")
    return head_sha != gh["head_sha"]


def _filter_by_diff(comments, changed_lines):
    """Keep only comments that target lines within the PR diff."""
    if not changed_lines:
        return list(comments)
    return [
        c for c in comments
        if (c.get("line", 0) - 1) in (changed_lines.get(c.get("path", "")) or [])
    ]


def _get_existing_markers(ctx, gh, pr_number):
    """Fetch all aspect-lint markers currently on the PR. Returns {marker: True}."""
    result = list_review_comments(
        ctx, token = gh["token"], owner = gh["owner"],
        repo = gh["repo"], pull_number = pr_number,
    )
    if not result["success"]:
        return {}
    markers = {}
    for c in result["comments"]:
        marker = _extract_comment_marker(c.get("body", ""))
        if marker:
            markers[marker] = True
    return markers


def _post_as_review(ctx, gh, pr_number, comments, existing_markers):
    """Post comments as a single grouped review, skipping duplicates."""
    to_post = [
        c for c in comments
        if _extract_comment_marker(c.get("body", "")) not in existing_markers
    ]
    if not to_post:
        return
    create_review(
        ctx, token = gh["token"], owner = gh["owner"],
        repo = gh["repo"], pull_number = pr_number,
        body = "Lint findings", event = "COMMENT",
        comments = to_post, commit_id = gh["head_sha"],
    )


def _post_individually(ctx, gh, pr_number, comments, existing_markers):
    """Post comments one at a time, skipping duplicates."""
    for c in comments:
        marker = _extract_comment_marker(c.get("body", ""))
        if marker and marker in existing_markers:
            continue
        result = create_review_comment(
            ctx, token = gh["token"], owner = gh["owner"],
            repo = gh["repo"], pull_number = pr_number,
            body = c["body"], path = c["path"],
            line = c.get("line"), commit_id = gh["head_sha"],
            side = c.get("side", "RIGHT"),
            start_line = c.get("start_line"),
            start_side = c.get("start_side"),
        )
        if result["success"] and marker:
            existing_markers[marker] = True


def _cleanup_comments(ctx, state):
    """Delete stale comments and deduplicate."""
    gh = state["github"]
    pr_number = state.get("pr_number")
    if not pr_number:
        return

    # Desired markers: diagnostics that are within the diff
    changed_lines = state.get("changed_lines", {})
    desired = {}
    for diag in state.get("diagnostics", []):
        lines = changed_lines.get(diag["file"])
        if lines and (diag["line"] - 1) in lines:
            marker = _build_comment_marker(diag["tool"], diag["file"], diag["line"], diag["rule_id"])
            desired[marker] = True

    # Fetch fresh state of comments on PR
    result = list_review_comments(
        ctx, token = gh["token"], owner = gh["owner"],
        repo = gh["repo"], pull_number = pr_number,
    )
    if not result["success"]:
        return

    # Group by marker
    by_marker = {}
    for c in result["comments"]:
        marker = _extract_comment_marker(c.get("body", ""))
        if not marker:
            continue
        if marker not in by_marker:
            by_marker[marker] = []
        by_marker[marker].append(c)

    # Delete stale (not desired) and duplicates (keep newest)
    for marker, comments in by_marker.items():
        if marker not in desired:
            for c in comments:
                delete_review_comment(
                    ctx, token = gh["token"], owner = gh["owner"],
                    repo = gh["repo"], comment_id = c["id"],
                )
        elif len(comments) > 1:
            by_id = sorted(comments, key = lambda c: c["id"])
            for c in by_id[:-1]:
                delete_review_comment(
                    ctx, token = gh["token"], owner = gh["owner"],
                    repo = gh["repo"], comment_id = c["id"],
                )


def make_github_strategy(base_strategy, token, owner, repo, mode = "grouped"):
    """
    Create a GitHub-aware strategy that wraps a base strategy with GitHub reporting.

    Args:
        base_strategy: The underlying Strategy to delegate to
        token: GitHub token
        owner: Repository owner
        repo: Repository name
        mode: "grouped" posts one review at the end,
              "streaming" posts comments individually as linters finish

    Returns:
        Strategy instance with GitHub integration
    """
    def setup(ctx, state):
        base_strategy.setup(ctx, state)
        state["github"] = {
            "token": token,
            "owner": owner,
            "repo": repo,
            "head_sha": ctx.std.env.var("GITHUB_SHA") or "",
            "pending_comments": [],
            "stale": False,
        }

    def process(ctx, state, filepath):
        # Accumulate diagnostics and build review comments
        diag_count_before = len(state.get("diagnostics", []))
        base_strategy.process(ctx, state, filepath)

        gh = state["github"]
        if gh["stale"]:
            return

        content = ctx.std.fs.read_to_string(filepath)
        sarif = parse_sarif(content)
        comments = sarif_to_review_comments(sarif)
        _enrich_with_suggestions(ctx, comments)

        # Stamp each comment with a hidden marker for identity tracking
        new_diagnostics = state.get("diagnostics", [])[diag_count_before:]
        for i, comment in enumerate(comments):
            if i < len(new_diagnostics):
                diag = new_diagnostics[i]
                marker = _build_comment_marker(
                    diag["tool"], diag["file"], diag["line"], diag["rule_id"])
                comment["body"] = marker + "\n" + comment["body"]

        gh["pending_comments"].extend(comments)

        # In streaming mode, post comments as they arrive
        if mode == "streaming":
            pr_number = state.get("pr_number")
            if not pr_number:
                return
            if "existing_markers" not in gh:
                gh["existing_markers"] = _get_existing_markers(ctx, gh, pr_number)
            ready = _filter_by_diff(gh["pending_comments"], state.get("changed_lines", {}))
            _post_individually(ctx, gh, pr_number, ready, gh["existing_markers"])
            gh["pending_comments"] = []

    def finish(ctx, state):
        gh = state["github"]

        if gh["stale"] or _check_staleness(ctx, state):
            gh["stale"] = True
            return base_strategy.finish(ctx, state)

        pr_number = state.get("pr_number")
        if pr_number:
            if mode == "grouped":
                existing = _get_existing_markers(ctx, gh, pr_number)
                ready = _filter_by_diff(gh["pending_comments"], state.get("changed_lines", {}))
                _post_as_review(ctx, gh, pr_number, ready, existing)
            _cleanup_comments(ctx, state)

        return base_strategy.finish(ctx, state)

    return Strategy(
        needs_machine = base_strategy.needs_machine,
        setup = setup,
        process = process,
        finish = finish,
    )
