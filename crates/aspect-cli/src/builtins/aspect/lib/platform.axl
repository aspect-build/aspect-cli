"""
Platform Configuration and Bazelrc Generation Library

Pure functions for reading platform/host configuration and generating bazelrc flags.
"""

DEFAULT_WORKFLOWS_DIR = "/etc/aspect/workflows"
DEFAULT_STORAGE_PATH = "/mnt/ephemeral"
DEFAULT_PLATFORM_DIR = DEFAULT_WORKFLOWS_DIR + "/platform"
DEFAULT_BIN_DIR = DEFAULT_WORKFLOWS_DIR + "/bin"

PLATFORM_CONFIG_KEYS = {
    "remote_cache_endpoint": "remote_cache_endpoint",
    "remote_cache_address": "remote_cache_address",
    "storage_path": "storage_path",
    "bessie_endpoint": "bessie_endpoint",
    "build_result_ui_base_url": "build_result_ui_base_url",
    "instance_id": "instance_id",
    "instance_name": "instance_name",
    "account": "account",
    "region": "region",
}


def read_platform_config(fs, platform_dir = DEFAULT_PLATFORM_DIR):
    """
    Read platform configuration from disk.

    Args:
        fs: Filesystem interface (ctx.std.fs)
        platform_dir: Path to platform config directory

    Returns:
        dict with platform config keys
    """
    config = {}

    for key, filename in PLATFORM_CONFIG_KEYS.items():
        path = platform_dir + "/" + filename
        if fs.exists(path):
            content = fs.read_to_string(path)
            if content:
                config[key] = content.strip()

    tokens_path = platform_dir + "/rosetta_api_tokens"
    if fs.exists(tokens_path):
        content = fs.read_to_string(tokens_path)
        if content:
            config["rosetta_api_tokens"] = json.decode(content)

    if "storage_path" not in config:
        config["storage_path"] = DEFAULT_STORAGE_PATH

    return config


def read_warming_config(fs, platform_dir = DEFAULT_PLATFORM_DIR):
    """
    Read warming-specific configuration from platform config files.

    Args:
        fs: Filesystem interface (ctx.std.fs)
        platform_dir: Path to platform config directory

    Returns:
        dict with optional keys: warming_bucket, warming_additional_paths
    """
    config = {}

    bucket_path = platform_dir + "/warming_bucket"
    if fs.exists(bucket_path):
        content = fs.read_to_string(bucket_path)
        if content:
            config["warming_bucket"] = content.strip()

    paths_path = platform_dir + "/warming_additional_paths"
    if fs.exists(paths_path):
        content = fs.read_to_string(paths_path)
        if content:
            config["warming_additional_paths"] = content.strip()

    return config


def read_host_config(env, io):
    """
    Read host/CI configuration from environment.

    Args:
        env: Environment interface (ctx.std.env)
        io: IO interface (ctx.std.io)

    Returns:
        dict with keys: supports_curses, scm_repo_name, ci_host
    """
    config = {
        "supports_curses": io.stdout.is_tty,
        "scm_repo_name": None,
        "ci_host": None,
    }

    if env.var("BUILDKITE_REPO"):
        config["ci_host"] = "buildkite"
        config["scm_repo_name"] = _parse_git_url_name(env.var("BUILDKITE_REPO"))
        config["supports_curses"] = True
    elif env.var("GITHUB_REPOSITORY"):
        config["ci_host"] = "github"
        repo = env.var("GITHUB_REPOSITORY")
        config["scm_repo_name"] = repo.split("/")[-1] if "/" in repo else repo
    elif env.var("CIRCLE_PROJECT_REPONAME"):
        config["ci_host"] = "circleci"
        config["scm_repo_name"] = env.var("CIRCLE_PROJECT_REPONAME")
    elif env.var("CI_PROJECT_NAME"):
        config["ci_host"] = "gitlab"
        config["scm_repo_name"] = env.var("CI_PROJECT_NAME")

    return config


def _parse_git_url_name(url):
    if not url:
        return None
    name = url.rstrip("/")
    if name.endswith(".git"):
        name = name[:-4]
    return name.split("/")[-1].split(":")[-1]


def parse_version(version_str):
    parts = version_str.split(".")
    major = int(parts[0]) if len(parts) > 0 else 0
    minor = int(parts[1]) if len(parts) > 1 else 0
    patch_str = parts[2].split("-")[0] if len(parts) > 2 else "0"
    patch = int(patch_str) if patch_str else 0
    return (major, minor, patch)


def version_satisfies(version, constraint):
    if not version or constraint == "*":
        return True

    v = parse_version(version)
    parts = constraint.split()
    for i in range(0, len(parts), 2):
        if i + 1 >= len(parts):
            break
        op = parts[i]
        target = parse_version(parts[i + 1])

        if op == "<" and not (v < target):
            return False
        elif op == "<=" and not (v <= target):
            return False
        elif op == ">" and not (v > target):
            return False
        elif op == ">=" and not (v >= target):
            return False
        elif op == "=" and v != target:
            return False

    return True


def _sanitize_filename(name):
    if not name:
        return ""
    result = ""
    for c in name.elems():
        if c.isalnum() or c in "-_.":
            result += c
        else:
            result += "_"
    return result


def get_bazelrc_flags(platform_config, host_config, bazel_version = None, root_dir = None):
    """
    Generate bazelrc flags from platform and host configuration.

    Args:
        platform_config: dict from read_platform_config()
        host_config: dict from read_host_config()
        bazel_version: str like "7.0.0" or None
        root_dir: absolute path to the workspace root directory

    Returns:
        (startup_flags, build_flags): two lists of flag strings
    """
    storage_path = platform_config.get("storage_path", DEFAULT_STORAGE_PATH)
    repo_name = host_config.get("scm_repo_name")
    subdir = _sanitize_filename(root_dir.rstrip("/").split("/")[-1]) if root_dir else "__main__"

    build_flags = []

    build_flags.append("--remote_upload_local_results")
    build_flags.append("--heap_dump_on_oom")
    build_flags.append("--generate_json_trace_profile")
    build_flags.append("--experimental_repository_cache_hardlinks")
    build_flags.append("--remote_accept_cached")

    if version_satisfies(bazel_version, "< 7"):
        build_flags.append("--incompatible_remote_results_ignore_disk")

    build_flags.append("--disk_cache=")
    build_flags.append("--remote_timeout=3600")
    build_flags.append("--remote_retries=360")
    build_flags.append("--grpc_keepalive_timeout=30s")

    if version_satisfies(bazel_version, "< 8"):
        build_flags.append("--noexperimental_remote_cache_compression")
    else:
        build_flags.append("--noremote_cache_compression")

    remote_cache_endpoint = platform_config.get("remote_cache_endpoint")
    if remote_cache_endpoint:
        build_flags.append("--remote_cache=" + remote_cache_endpoint)

    remote_cache_address = platform_config.get("remote_cache_address")
    if remote_cache_address:
        build_flags.append("--remote_bytestream_uri_prefix=" + remote_cache_address)

    build_flags.append("--repository_cache=" + storage_path + "/caches/repository")

    startup_flags = []

    if repo_name:
        sanitized = _sanitize_filename(repo_name)
        startup_flags.append("--output_user_root=" + storage_path + "/bazel/" + sanitized + "/" + subdir)
        startup_flags.append("--output_base=" + storage_path + "/output/" + sanitized + "/" + subdir)
    else:
        startup_flags.append("--output_user_root=" + storage_path + "/bazel/" + subdir)
        startup_flags.append("--output_base=" + storage_path + "/output/" + subdir)

    return (startup_flags, build_flags)
